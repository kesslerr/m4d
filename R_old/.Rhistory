install.packages("targets")
install.packages("shiny")
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
install.packages(c("biglm", "dplyr", "ggplot2", "readr", "targets", "tidyr"))
tar_manifest(fields = all_of("command"))
library(targets)
source("R/functions.R")
tar_option_set(packages = c("data.table", "tidyverse", "lmerTest", "ggplot2"))
list(
tar_target(folder, "data.csv", format = "folder"),
tar_target(data, get_data(folder))
#tar_target(model, fit_model(data)),
#tar_target(plot, plot_model(model, data))
)
list(
tar_target(folder, "data.csv", format = "file"),
tar_target(data, get_data(folder))
#tar_target(model, fit_model(data)),
#tar_target(plot, plot_model(model, data))
)
tar_manifest(fields = all_of("command"))
pwd
getwd()
tar_manifest(fields = all_of("command"))
tar_manifest(fields = all_of("command"))
?tar_manifest
tar_visnetwork()
tar_visnetwork()
tar_option_set(packages = c("data.table", "tidyverse", "lmerTest", "ggplot2"))
list(
tar_target(folder, "/Users/roman/GitHub/m4d/models/eegnet/", format = "file"),
tar_target(data, get_data(folder))
#tar_target(model, fit_model(data)),
#tar_target(plot, plot_model(model, data))
)
tar_manifest(fields = all_of("command"))
library(targets)
source("R/functions.R")
tar_option_set(packages = c("tibble", "data.table", "tidyverse", "lmerTest", "ggplot2"))
list(
tar_target(folder, "/Users/roman/GitHub/m4d/models/eegnet/", format = "file"),
tar_target(data, get_data(folder))
#tar_target(model, fit_model(data)),
#tar_target(plot, plot_model(model, data))
)
tar_manifest(fields = all_of("command"))
use_targets()
library(targets)
use_targets()
library(targets)
use_targets()
library(targets)
use_targets()
library(targets)
# Set target options:
tar_option_set(
packages = c("tibble", "data.table", "tidyverse", "lmerTest", "ggplot2") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
tar_source()
list(
# tar_target(
#   name = data,
#   command = tibble(x = rnorm(100), y = rnorm(100))
#   # format = "qs" # Efficient storage for general data objects.
# ),
# tar_target(
#   name = model,
#   command = coefficients(lm(y ~ x, data = data))
# )
tar_target(name = folder,
command = "/Users/roman/GitHub/m4d/models/eegnet/",
format = "file"),
tar_target(name = data,
command = get_data(folder))
)
# Replace the target list below with your own:
list(
# tar_target(
#   name = data,
#   command = tibble(x = rnorm(100), y = rnorm(100))
#   # format = "qs" # Efficient storage for general data objects.
# ),
# tar_target(
#   name = model,
#   command = coefficients(lm(y ~ x, data = data))
# )
tar_target(name = folder,
command = "/Users/roman/GitHub/m4d/models/eegnet/"),
#format = "file"),
tar_target(name = data,
command = get_data(folder))
)
tar_manifest(fields = all_of("command"))
$stderr
.Last.error
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(lmerTest)
install.packages("lmerTest")
library(tidyverse)
library(lmerTest)
library(data.table)
library(ggplot2)
# Define the directory containing the subfolders
model_folder = "/Users/roman/GitHub/m4d/models/eegnet/"
# Get subdirectory names
#subdirectory_names <- basename(dirname(model_folder))
experiments <- list.dirs(model_folder, full.names = FALSE, recursive = FALSE)
subjects <- list.dirs(paste0(model_folder, experiments[1]), full.names = FALSE, recursive = FALSE)
new_column_names <- c('ref','hpf','lpf','emc','mac','base','det','ar')
# Initialize an empty data table to store the concatenated data
concatenated_data <- NULL
# DEBUG
experiment = experiments[1]
subject = subjects[1]
for (experiment in experiments){
for (subject in subjects){
# List all CSV files in the subdirectory
files <- list.files(path = paste0(model_folder, experiment, '/', subject), pattern = "\\.csv$", full.names = TRUE)
# Read and vertically concatenate the CSV files
data <- lapply(files, fread)
data <- rbindlist(data, fill = TRUE)
# Split the column at each "_" and name the new columns
data[, (new_column_names) := tstrsplit(forking_path, "_", fixed = TRUE)]
# Add subdirectory names as separate columns
data[, "experiment" := rep(experiment,length(files))]
data[, "subject" := rep(subject,length(files))]
# Delete the "forking_path" column
data[, forking_path := NULL]
concatenated_data <- rbindlist(list(concatenated_data, data), fill = TRUE)
}
}
# recode variables
# Assuming 'hpf' is a factor variable in your data
concatenated_data$hpf <- factor(concatenated_data$hpf, levels = c("None", "0.1", "0.5"))
concatenated_data$lpf <- factor(concatenated_data$lpf, levels = c("None", "6", "20", "45"))
concatenated_data$ref <- factor(concatenated_data$ref, levels = c("average", "Cz", "P9P10"))
concatenated_data$emc <- factor(concatenated_data$emc, levels = c("None", "ica"))
concatenated_data$mac <- factor(concatenated_data$mac, levels = c("None", "ica"))
concatenated_data$base <- factor(concatenated_data$base, levels = c("200ms", "400ms"))
concatenated_data$det <- factor(concatenated_data$det, levels = c("offset", "linear"))
concatenated_data$ar <- factor(concatenated_data$ar, levels = c("False", "True"))
concatenated_data$experiment <- factor(concatenated_data$experiment)
# Output the combined data
print(concatenated_data)
# Run the R scripts in the R/ folder with your custom functions:
tar_source()
# tar_source("other_functions.R") # Source other scripts as needed.
# Replace the target list below with your own:
list(
# tar_target(
#   name = data,
#   command = tibble(x = rnorm(100), y = rnorm(100))
#   # format = "qs" # Efficient storage for general data objects.
# ),
# tar_target(
#   name = model,
#   command = coefficients(lm(y ~ x, data = data))
# )
tar_target(name = folder,
command = "/Users/roman/GitHub/m4d/R/data/eegnet/"),
#format = "file"),
tar_target(name = data,
command = get_data(folder))
)
tar_manifest(fields = all_of("command"))
# Define the directory containing the subfolders
model_folder = "/Users/roman/GitHub/m4d/R/data/eegnet/"
# Get subdirectory names
#subdirectory_names <- basename(dirname(model_folder))
experiments <- list.dirs(model_folder, full.names = FALSE, recursive = FALSE)
subjects <- list.dirs(paste0(model_folder, experiments[1]), full.names = FALSE, recursive = FALSE)
new_column_names <- c('ref','hpf','lpf','emc','mac','base','det','ar')
# Initialize an empty data table to store the concatenated data
concatenated_data <- NULL
# DEBUG
experiment = experiments[1]
subject = subjects[1]
for (experiment in experiments){
for (subject in subjects){
# List all CSV files in the subdirectory
files <- list.files(path = paste0(model_folder, experiment, '/', subject), pattern = "\\.csv$", full.names = TRUE)
# Read and vertically concatenate the CSV files
data <- lapply(files, fread)
data <- rbindlist(data, fill = TRUE)
# Split the column at each "_" and name the new columns
data[, (new_column_names) := tstrsplit(forking_path, "_", fixed = TRUE)]
# Add subdirectory names as separate columns
data[, "experiment" := rep(experiment,length(files))]
data[, "subject" := rep(subject,length(files))]
# Delete the "forking_path" column
data[, forking_path := NULL]
concatenated_data <- rbindlist(list(concatenated_data, data), fill = TRUE)
}
}
# recode variables
# Assuming 'hpf' is a factor variable in your data
concatenated_data$hpf <- factor(concatenated_data$hpf, levels = c("None", "0.1", "0.5"))
concatenated_data$lpf <- factor(concatenated_data$lpf, levels = c("None", "6", "20", "45"))
concatenated_data$ref <- factor(concatenated_data$ref, levels = c("average", "Cz", "P9P10"))
concatenated_data$emc <- factor(concatenated_data$emc, levels = c("None", "ica"))
concatenated_data$mac <- factor(concatenated_data$mac, levels = c("None", "ica"))
concatenated_data$base <- factor(concatenated_data$base, levels = c("200ms", "400ms"))
concatenated_data$det <- factor(concatenated_data$det, levels = c("offset", "linear"))
concatenated_data$ar <- factor(concatenated_data$ar, levels = c("False", "True"))
concatenated_data$experiment <- factor(concatenated_data$experiment)
# Output the combined data
print(concatenated_data)
# Define the directory containing the subfolders
model_folder = "/Users/roman/GitHub/m4d/R/data/eegnet/"
# Get subdirectory names
#subdirectory_names <- basename(dirname(model_folder))
experiments <- list.dirs(model_folder, full.names = FALSE, recursive = FALSE)
subjects <- list.dirs(paste0(model_folder, experiments[1]), full.names = FALSE, recursive = FALSE)
new_column_names <- c('ref','hpf','lpf','emc','mac','base','det','ar')
# Initialize an empty data table to store the concatenated data
concatenated_data <- NULL
for (experiment in experiments){
for (subject in subjects){
# List all CSV files in the subdirectory
files <- list.files(path = paste0(model_folder, experiment, '/', subject), pattern = "\\.csv$", full.names = TRUE)
# Read and vertically concatenate the CSV files
data <- lapply(files, fread)
data <- rbindlist(data, fill = TRUE)
# Split the column at each "_" and name the new columns
data[, (new_column_names) := tstrsplit(forking_path, "_", fixed = TRUE)]
# Add subdirectory names as separate columns
data[, "experiment" := rep(experiment,length(files))]
data[, "subject" := rep(subject,length(files))]
# Delete the "forking_path" column
data[, forking_path := NULL]
concatenated_data <- rbindlist(list(concatenated_data, data), fill = TRUE)
}
}
# Assuming 'hpf' is a factor variable in your data
concatenated_data$hpf <- factor(concatenated_data$hpf, levels = c("None", "0.1", "0.5"))
concatenated_data$lpf <- factor(concatenated_data$lpf, levels = c("None", "6", "20", "45"))
concatenated_data$ref <- factor(concatenated_data$ref, levels = c("average", "Cz", "P9P10"))
concatenated_data$emc <- factor(concatenated_data$emc, levels = c("None", "ica"))
concatenated_data$mac <- factor(concatenated_data$mac, levels = c("None", "ica"))
concatenated_data$base <- factor(concatenated_data$base, levels = c("200ms", "400ms"))
concatenated_data$det <- factor(concatenated_data$det, levels = c("offset", "linear"))
concatenated_data$ar <- factor(concatenated_data$ar, levels = c("False", "True"))
concatenated_data$experiment <- factor(concatenated_data$experiment)
data_folder =  "/Users/roman/GitHub/m4d/R/data/"
write.csv(concatenated_data, paste0(model_folder, "eegnet.csv"), row.names = FALSE)
# Load packages required to define the pipeline:
library(targets)
# library(tarchetypes) # Load other packages as needed.
# Set target options:
tar_option_set(
packages = c("tibble", "data.table", "tidyverse", "lmerTest", "ggplot2") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source()
# tar_source("other_functions.R") # Source other scripts as needed.
# Replace the target list below with your own:
list(
# tar_target(
#   name = data,
#   command = tibble(x = rnorm(100), y = rnorm(100))
#   # format = "qs" # Efficient storage for general data objects.
# ),
# tar_target(
#   name = model,
#   command = coefficients(lm(y ~ x, data = data))
# )
tar_target(name = file,
command = "/Users/roman/GitHub/m4d/R/data/eegnet_erpcore.csv"),
#format = "file"),
tar_target(name = data,
command = get_data(folder))
)
tar_manifest(fields = all_of("command"))
tar_source()
# Replace the target list below with your own:
list(
# tar_target(
#   name = data,
#   command = tibble(x = rnorm(100), y = rnorm(100))
#   # format = "qs" # Efficient storage for general data objects.
# ),
# tar_target(
#   name = model,
#   command = coefficients(lm(y ~ x, data = data))
# )
tar_target(name = file,
command = "data/eegnet_erpcore.csv",
format = "file"),
tar_target(name = data,
command = get_data(folder))
)
tar_manifest(fields = all_of("command"))
tar_manifest()
list(
tar_target(name = file,
command = "data/eegnet_erpcore.csv",
format = "file"),
tar_target(name = data,
command = get_data(file))
)
tar_manifest()
# Run the R scripts in the R/ folder with your custom functions:
tar_source()
# tar_source("other_functions.R") # Source other scripts as needed.
# Replace the target list below with your own:
list(
tar_target(name = file,
command = "data/eegnet_erpcore.csv",
format = "file"),
tar_target(name = data,
command = get_data(file))
)
tar_manifest()
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
# Load packages required to define the pipeline:
library(targets)
# library(tarchetypes) # Load other packages as needed.
# Set target options:
tar_option_set(
packages = c("tibble", "data.table", "tidyverse", "lmerTest", "ggplot2") # Packages that your targets need for their tasks.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source()
# tar_source("other_functions.R") # Source other scripts as needed.
# Replace the target list below with your own:
list(
tar_target(name = file,
command = "data/eegnet_erpcore.csv",
format = "file"),
tar_target(name = data,
command = get_data(file))
)
tar_manifest()
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
# Load packages required to define the pipeline:
library(targets)
# library(tarchetypes) # Load other packages as needed.
# Set target options:
tar_option_set(
packages = c("tibble", "data.table", "tidyverse", "lmerTest", "ggplot2") # Packages that your targets need for their tasks.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source()
# tar_source("other_functions.R") # Source other scripts as needed.
# Replace the target list below with your own:
list(
tar_target(name = file,
command = "data/eegnet_erpcore.csv",
format = "file"),
tar_target(name = data,
command = get_data(file))
)
tar_manifest()
tar_make()
get_data <- function(file) {
data <- read_csv(file, col_types = cols())
return(data)
}
testdata = get_data("data/eegnet_erpcore.csv")
get_data <- function(file) {
data <- read_csv(file) #, col_types = cols())
#data <- read.csv(paste0(data_folder, "eegnet.csv"))
return(data)
}
testdata = get_data("data/eegnet_erpcore.csv")
source("~/GitHub/m4d/R/_targets.R")
tar_manifest()
source("~/GitHub/m4d/R/_targets.R")
tar_manifest()
