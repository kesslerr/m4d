---
title: "Multiverse4Decoding"
author: "Roman Kessler"
format: html
editor: visual
---

```{r}
library(targets)
library(tarchetypes)
library(dplyr)
options(dplyr.print_max = 1e9)

```

## Multiverse for Decoding

In short, decoding accuracies have been calculated for each participant, each experiment, and each variation in the pipeline. Marginal means have been calculated and plotted in the following.

The original idea was to replicate the HLM from Clayson et al (2021, Neuroimage). However, the HLM might be faulty, and significances were probably overestimated in Clayson. This needs further investigation with HLM Experts to find out.

For now, statistics has been done by averaging over 2 levels of a variable (e.g., variable "autoreject", levels "TRUE" and "FALSE"), by marginalizing out all other variables. Then, one value for each subjects and level is put into a (paired-)t-test (depending on the data structure). Benjamini Yekutieli FDR correction is applied for all pairwise comparisons within a variable (p.adj, not shown in printed table).

The T-Test might be replaced by something non-parametric.

Tests have been calculated across experiments and age groups within a dataset, or for each single experiment and age group (below).

-   ERPCORE: adult data set containing experiments (ERN, LRP, MMN, N170, N2pc, N400, P3)
-   MIPDB: children / teenagers (experiment LRP, for different age groups)

The Raincloud plots show general data distributions.

The Paired-Plots are not pretty, but there one can nicely see why comparisons get significant, because for some variations of steps, there is a very systematic but tiny difference in accuracy for each participant.

```{r}
tar_visnetwork()
```

```{r}
tar_visnetwork(targets_only=TRUE, label=c("description", "branches"))
```

## Overview of decoding performances

### ERPCORE

```{r, fig.width=8,fig.height=6}
#| echo: false
tar_read(overview)

```

## Sliding Window - Example UNIVERSE result

```{r, fig.width=7,fig.height=10}
#| echo: false
tar_read(timeresolved_luck)
```

## Influence of analysis choises - (M)LM and EMM

### Estimated Marginal Means & Differences

#### EEGNET

##### Means

```{r}
tar_read(eegnet_HLM_emm_means_comb)
```

##### Contrasts / Pairwise differences

```{r}
tar_read(eegnet_HLM_emm_contrasts_comb)
```

##### Omnibus F-Test per facet (Experiment-Model and Preprocessing Step)

```{r}
tar_read(eegnet_HLM_emm_omni_comb)
```

#### Sliding Window

##### Means

```{r}
tar_read(sliding_LM_emm_means_comb)
```

##### Contrasts / Pairwise differences

```{r}
tar_read(sliding_LM_emm_contrasts_comb)
```

##### Omnibus F-Test per facet (Experiment-Model and Preprocessing Step)

```{r}
tar_read(sliding_LM_emm_omni_comb)
```

#### 

### Relative performance differences

```{r, fig.width=10,fig.height=10}
#| echo: false
tar_read(heatmaps)
```

## Model diagnostics

-   Mixed-effects models are somewhat robust to mild deviations from normality, especially with more random effects.

-   Visual inspection of diagnostic plots is often more informative than relying solely on p-values from these tests.

-   Tests often focus on residuals at the observation level, whereas mixed-effects models also have random effects variability to consider.

### QQ-Plots

-   **What to look for:**

    -   Ideally, the majority of the residuals should fall close to the straight diagonal line. This indicates that the residuals are approximately normally distributed.

-   **What you shouldn't see:**

    -   Substantial deviations from the diagonal line, especially in the tails of the distribution. This suggests the normality assumption of the model might be violated.

```{r, fig.width=7,fig.height=7}
#| echo: false
tar_read(eegnet_HLM_qq_comb)
tar_read(sliding_LM_qq_comb)
```

### Residuals vs Fitted - Plots

-   **What to look for:**

    -   **Linearity:** Ideally, there should be no clear pattern in the residuals (they should be randomly scattered around zero). A curved pattern might indicate a nonlinear relationship you haven't modeled.

    -   **Homoscedasticity:** The spread of the residuals should be relatively constant across fitted values. If the spread increases or decreases, it suggests non-constant variance (heteroscedasticity).

    -   **Outliers:** Look for points that lie far away from the majority of the residuals. These could be influential observations.

-   **What you shouldn't see:**

    -   Clear patterns (e.g., U-shapes, funnel shapes).

    -   Significant changes in the spread of residuals across fitted values.

    -   Extreme outliers.

```{r, fig.width=7,fig.height=7}
#| echo: false
tar_read(eegnet_HLM_rvf_comb)
tar_read(sliding_LM_rvf_comb)
```

### Scale-Location-Plots

-   **What to look for:**

    -   Ideally, the line should be relatively horizontal, indicating constant variance (homoscedasticity).

-   **What you shouldn't see:**

    -   Strong trends or patterns in the line suggesting changing variance across fitted values (heteroscedasticity).

```{r, fig.width=7,fig.height=7}
#| echo: false
tar_read(eegnet_HLM_sasrvf_comb)
tar_read(sliding_LM_sasrvf_comb)
```

## 
